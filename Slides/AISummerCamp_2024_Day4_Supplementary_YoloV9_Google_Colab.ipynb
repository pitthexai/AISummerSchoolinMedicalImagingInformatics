{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f634423",
      "metadata": {
        "id": "9f634423"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics ttach roboflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b54f07db",
      "metadata": {
        "id": "b54f07db"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import regex as re\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "from roboflow import Roboflow\n",
        "from PIL import Image\n",
        "\n",
        "from ultralytics import YOLO\n",
        "\n",
        "import yaml\n",
        "from zipfile import ZipFile"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7fb08b2",
      "metadata": {
        "id": "c7fb08b2"
      },
      "source": [
        "### Data Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf = Roboflow(api_key=\"6kQe6c01IeFKXTyChZff\")\n",
        "project = rf.workspace(\"aisummerschool2024\").project(\"tka-localization-fmeno\")\n",
        "version = project.version(1)\n",
        "dataset = version.download(\"yolov9\", location=\"/content/datasets/TKA-Localization\")\n"
      ],
      "metadata": {
        "id": "KTxofIEo1QM-"
      },
      "id": "KTxofIEo1QM-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.location"
      ],
      "metadata": {
        "id": "FleRJe1C1-22"
      },
      "id": "FleRJe1C1-22",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "90891a8e",
      "metadata": {
        "id": "90891a8e"
      },
      "source": [
        "### Few-Shot YOLOv8 Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32fde93c",
      "metadata": {
        "id": "32fde93c"
      },
      "outputs": [],
      "source": [
        "# Import YOLO from Ultralytics library\n",
        "from ultralytics import YOLO\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0b15e32",
      "metadata": {
        "id": "e0b15e32"
      },
      "outputs": [],
      "source": [
        "model = YOLO(\"yolov9c.pt\")  # load a pretrained model (recommended for training)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.name"
      ],
      "metadata": {
        "id": "L9qNbxYf4-HY"
      },
      "id": "L9qNbxYf4-HY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fb5c416",
      "metadata": {
        "id": "6fb5c416"
      },
      "outputs": [],
      "source": [
        "# Train on few-shot dataset\n",
        "# Verify the correct path to your data.yaml file\n",
        "data_yaml_path = f'{dataset.location}/data.yaml'\n",
        "print(f\"Checking for data.yaml at: {data_yaml_path}\")\n",
        "\n",
        "if os.path.exists(data_yaml_path):\n",
        "    print(\"data.yaml found. Proceeding with training.\")\n",
        "    # Train on few-shot dataset\n",
        "    metrics = model.train(data=data_yaml_path, epochs=100)\n",
        "else:\n",
        "    print(\"data.yaml not found. Please check the path and ensure the file exists.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ee317b8",
      "metadata": {
        "id": "3ee317b8"
      },
      "outputs": [],
      "source": [
        "metrics = model.val()  # evaluate model performance on the validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd1408a0",
      "metadata": {
        "id": "fd1408a0"
      },
      "outputs": [],
      "source": [
        "# Evaluate on test set\n",
        "results = model.val(split=\"test\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "id": "rE2iOfV5Ga4H"
      },
      "id": "rE2iOfV5Ga4H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0938259f",
      "metadata": {
        "id": "0938259f"
      },
      "outputs": [],
      "source": [
        "# Single image prediction\n",
        "result = model.predict(\"/content/datasets/TKA-Localization/test/images/00940404_jpg.rf.952202247cb2c0871f612ca98c8b2c2a.jpg\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0895a109",
      "metadata": {
        "id": "0895a109"
      },
      "outputs": [],
      "source": [
        "# Multiple image prediction\n",
        "trained_model_pth = \"runs/detect/train/weights/best.pt\"\n",
        "model = YOLO(trained_model_pth)\n",
        "\n",
        "test_root = f\"/content/datasets/TKA-Localization/test/images\"\n",
        "test_imgs = [os.path.join(test_root, img) for img in os.listdir(test_root)]\n",
        "result = model.predict(test_imgs, save=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_iou(box1, box2):\n",
        "    \"\"\"\n",
        "    Calculate the Intersection over Union (IoU) of two bounding boxes.\n",
        "    Each box is defined as a list of 4 elements [x1, y1, x2, y2]\n",
        "    where (x1, y1) is the top-left corner, and (x2, y2) is the bottom-right corner.\n",
        "    \"\"\"\n",
        "    x1 = max(box1[0], box2[0])\n",
        "    y1 = max(box1[1], box2[1])\n",
        "    x2 = min(box1[2], box2[2])\n",
        "    y2 = min(box1[3], box2[3])\n",
        "\n",
        "    # Calculate the area of intersection rectangle\n",
        "    inter_area = max(0, x2 - x1) * max(0, y2 - y1)\n",
        "\n",
        "    # Calculate the area of both bounding boxes\n",
        "    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
        "    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
        "\n",
        "    # Calculate the intersection over union by taking the intersection\n",
        "    # area and dividing it by the sum of prediction + ground-truth\n",
        "    # areas - the intersection area.\n",
        "    iou = inter_area / float(box1_area + box2_area - inter_area)\n",
        "\n",
        "    return iou"
      ],
      "metadata": {
        "id": "g1Z4ty-HM2fM"
      },
      "id": "g1Z4ty-HM2fM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_ground_truth_to_coco(x, y, w, h, img_width=600, img_height=600):\n",
        "    # Convert normalized coordinates to pixel coordinates\n",
        "    x *= img_width\n",
        "    y *= img_height\n",
        "    w *= img_width\n",
        "    h *= img_height\n",
        "\n",
        "    # Calculate top-left and bottom-right corners\n",
        "    x1 = x - w /2\n",
        "    y1 = y - h /2\n",
        "    x2 = x + w /2\n",
        "    y2 = y + h /2\n",
        "\n",
        "    return [x1, y1, x2, y2]"
      ],
      "metadata": {
        "id": "jeYtlbvhe_i-"
      },
      "id": "jeYtlbvhe_i-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_ground_truth_box(image_path):\n",
        "    with open(image_path, 'r') as file:\n",
        "        ground_truth_boxes = []\n",
        "        lines = file.readlines()\n",
        "        for line in lines:\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) == 5:\n",
        "                _, x_center, y_center, width, height = map(float, parts)\n",
        "                ground_truth_boxes.append([x_center, y_center, width, height])\n",
        "    return ground_truth_boxes"
      ],
      "metadata": {
        "id": "5ewRt8wYWzFS"
      },
      "id": "5ewRt8wYWzFS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for img in test_imgs:\n",
        "    label_pth = img.replace(\"images\", \"labels\")\n",
        "    label_pth = label_pth.replace(\".jpg\", \".txt\")\n",
        "    ground_truth_boxes = get_ground_truth_box(label_pth)\n",
        "\n",
        "    results = model.predict(img)\n",
        "    bboxes = results[0].boxes.xyxy.cpu().numpy()\n",
        "    for pred_box in bboxes:\n",
        "        best_iou = 0\n",
        "        best_gt_box = None\n",
        "        for gt_box in ground_truth_boxes:\n",
        "            conversion = convert_ground_truth_to_coco(gt_box[0], gt_box[1], gt_box[2], gt_box[3])\n",
        "            iou = calculate_iou(pred_box, conversion)\n",
        "            if iou > best_iou:\n",
        "                best_iou = iou\n",
        "                best_gt_box = conversion\n",
        "\n",
        "        print(f\"Image {img}, Predicted box: {pred_box}, Best matching ground truth box: {best_gt_box}, IoU: {best_iou}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "lTxF3EfMNA4Z"
      },
      "id": "lTxF3EfMNA4Z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wXYR_Kwsg3rZ"
      },
      "id": "wXYR_Kwsg3rZ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:pytorch110_p38_gpu_v1]",
      "language": "python",
      "name": "conda-env-pytorch110_p38_gpu_v1-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}